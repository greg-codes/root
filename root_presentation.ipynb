{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Ad Auction Dataset\n",
    "## Team: The Puffy Shirts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data set:\n",
    "\n",
    "    30 days of CSV files    \n",
    "    rows are winning bids in a second-price auction\n",
    "    contains information on the target user/platform, the UTC timestamp, the app, the exchange, etc...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges of this data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large data set:\n",
    "\n",
    "- 1.42 GB as .zip / 8.19 GB as .csv\n",
    "    \n",
    "- 36.3M rows, 26 columns\n",
    "    \n",
    "Highly unbalanced categorical classification problem:\n",
    "\n",
    "- 1.57M clicks (4.3% of rows)\n",
    "    \n",
    "- 2,109 installs (0.0058% of rows, 0.13% of clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.dpi'] = 240 # fix high-dpi display scaling issues\n",
    "\n",
    "sys.path.append(os.getcwd()) # add cwd to path\n",
    "\n",
    "from zip_codes import ZC # zip code database\n",
    "import load_file as lf # file i/o\n",
    "import myplots as mp # my plotting functions\n",
    "zc = ZC('') # initialize zip code class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_27 = '2019-04-27.csv'\n",
    "data_dir = r'C:\\PythonBC\\RootData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "df_27 = pd.read_csv( os.path.join(data_dir, fname_27))\n",
    "end = time.time()\n",
    "print(f'loading {fname_27} with default pd.read_csv() settings takes'\n",
    "      + f' {end-start:3.2f} seconds and {lf.mem_usage(df_27)} of RAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some columns can be immediately dropped:\n",
    "- auction_id (meaningless string)\n",
    "- platform_os (all 'Android' or '-1')\n",
    "- app_bundle (all the same)\n",
    "- year (UTC time)\n",
    "- month (UTC time)\n",
    "- day (UTC time)\n",
    "- day_of_week (UTC time, incorrectly calculated)\n",
    "- hour (UTC time)\n",
    "- creative_size (redundant with creative_type)\n",
    "\n",
    "most columns are categorical with only a few unique values:\n",
    "- inventory_source (only 4 possible values)\n",
    "- category\n",
    "- platform_bandwidth\n",
    "- platform_carrier\n",
    "- platform_device_make (only 5 possible values)\n",
    "- platform_device_model\n",
    "- platform_device_screen_size\n",
    "- geo_zip\n",
    "\n",
    "some are boolean:\n",
    "- inventory_interstitial\n",
    "- rewarded\n",
    "- clicks\n",
    "- installs\n",
    "\n",
    "some columns need additional work:\n",
    "- geo_zip ('43212.0' >>> '43212')\n",
    "- category & segments are unsorted string lists\n",
    "\n",
    "some columns have multiple nan values:\n",
    "- platform_carrier\n",
    "- platform_device_make\n",
    "- platform_device_model\n",
    "- platform_device_screen_size\n",
    "\n",
    "The function lf.load_data() drops the useless columns and cleans & downcasts the others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#df_27 = lf.load_wrapper(fname=fname_27, data_dir=data_dir)\n",
    "df_27 = lf.load_data(fname=fname_27, data_dir=data_dir)\n",
    "end = time.time()\n",
    "print(f'loading {fname_27} with downcasting takes {end-start:3.2f}'\n",
    "      + f' seconds and {lf.mem_usage(df_27)} of RAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these tricks we reduce the RAM usage by a factor of **9.1**, but increase the load time by 43%. With this RAM reduction we can comfortably load the entire dataset into memory (~ 850 MB).\n",
    "\n",
    "We can quickly save the processed dataframe to disk using pd.to_parquet():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_save = time.time()\n",
    "lf.temp_save(df_27, fname=os.path.join(data_dir, fname_27.split('.')[0]+'.gzip'))\n",
    "end_save = time.time()\n",
    "df_27 = lf.temp_load( os.path.join(data_dir, fname_27.split('.')[0]+'.gzip') )\n",
    "end_load = time.time()\n",
    "\n",
    "print(f'saving to .gzip takes {end_save-start_save:3.2f}'\n",
    "      + f' seconds and loading from .gzip takes {end_load-end_save:3.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because parquet is so fast, it makes sense to pre-process all the data and save it to disk for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the geo_zip column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a zip code database (https://www.unitedstateszipcodes.org/zip-code-database/) to get local information for each bid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myzip = ['43210']\n",
    "print(f'zip code {myzip[0]}:')\n",
    "print( f'   state: {zc.zip_to_state_2(myzip)[0]}' )\n",
    "print( f'   county: {zc.zip_to_county_2(myzip)[0]}' )\n",
    "print( f'   timezone: {zc.zip_to_tz_2(myzip)[0]}' )\n",
    "print( f'   coordinates: {zc.zip_to_lat_2(myzip)[0], zc.zip_to_lon_2(myzip)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the local time zone, we can shift bid_timestamp_utc to local time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'UTC timestamp = {df_27.bid_timestamp_utc.iloc[0]}')\n",
    "print(f'local timestamp = {df_27.bid_timestamp_utc.iloc[0].tz_convert(\"America/New_York\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is slow, so run it on each .csv file separately and combine the results at the end.\n",
    "\n",
    "With the local timestamp, we can extract quantities like hour, day and day_of_week.\n",
    "\n",
    "The functions reshape_files() and local_hour_creator() do the aforementioned preprocessing and save each column as a .gzip file. This step takes about 30-40 minutes on a laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization: maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the data in memory, we can make visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choropleths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "state_geo = 'us-states.json' # local copy of json file\n",
    "\n",
    "# load relevant data from disk\n",
    "data_dir = r'C:\\PythonBC\\RootData'\n",
    "df_clicks = lf.temp_load( os.path.join(data_dir, 'clicks.gzip')  )\n",
    "df_state = lf.temp_load( os.path.join(data_dir, 'state.gzip')  )\n",
    "df_installs = lf.temp_load( os.path.join(data_dir, 'installs.gzip')  )\n",
    "frames = [df_state, df_clicks, df_installs]\n",
    "df = pd.concat(frames, axis=1)\n",
    "\n",
    "# number of clicks per state\n",
    "dfstates = df.groupby('state').sum()['clicks'].to_frame()\n",
    "dfstates.reset_index(level=0, inplace=True)\n",
    "\n",
    "# number of bids per state\n",
    "dfstates2 = df.groupby('state').count()['clicks'].to_frame()\n",
    "dfstates2.reset_index(level=0, inplace=True)\n",
    "dfstates2.rename(index=str, columns={\"state\": \"state\", \"clicks\": \"bids\"})\n",
    "\n",
    "# number of installs per state\n",
    "dfstates3 = df.groupby('state').sum()['installs'].to_frame()\n",
    "dfstates3.reset_index(level=0, inplace=True)\n",
    "dfstates3.rename(index=str, columns={\"state\": \"state\", \"clicks\": \"installs\"})\n",
    "\n",
    "# build new dataframe\n",
    "bids = dfstates2.clicks.values\n",
    "clicks = dfstates.clicks.values\n",
    "installs = np.asarray(dfstates3.installs)\n",
    "state = dfstates.state.values\n",
    "clickrate = 100*np.divide(clicks, bids)\n",
    "installrate = 100*np.divide(installs, bids)\n",
    "frames = {\"state\": state, \"bids\": bids, \"clicks\": clicks, \"installs\": installs, \"clickrate\":clickrate, \"installrate\": installrate}\n",
    "df_rate = pd.DataFrame(data=frames)\n",
    "df_rate_nonzero = df_rate[df_rate.clickrate > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickrate_m = folium.Map(location=[39.50, -98.35], zoom_start=4) # lower 48\n",
    "folium.Choropleth(\n",
    "    geo_data=state_geo,\n",
    "    name='choropleth',\n",
    "    data=df_rate_nonzero,\n",
    "    columns=['state', 'clickrate'],\n",
    "    key_on='feature.id',\n",
    "    fill_color='YlGn',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='click rate (%)'\n",
    ").add_to(clickrate_m)\n",
    "folium.LayerControl().add_to(clickrate_m)\n",
    "clickrate_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "installrate_m = folium.Map(location=[39.50, -98.35], zoom_start=4) # lower 48\n",
    "folium.Choropleth(\n",
    "    geo_data=state_geo,\n",
    "    name='choropleth',\n",
    "    data=df_rate_nonzero,\n",
    "    columns=['state', 'installrate'],\n",
    "    key_on='feature.id',\n",
    "    fill_color='YlGn',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='install rate (%)'\n",
    ").add_to(installrate_m)\n",
    "folium.LayerControl().add_to(installrate_m)\n",
    "installrate_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMap\n",
    "\n",
    "zipc = lf.temp_load( os.path.join(data_dir, 'geo_zip.gzip'))\n",
    "click = lf.temp_load( os.path.join(data_dir, 'clicks.gzip'))\n",
    "df = pd.concat([zipc,click],axis=1)\n",
    "\n",
    "dftest = df.query('clicks == True')\n",
    "dftest = pd.DataFrame(dftest.geo_zip.value_counts())\n",
    "df = pd.DataFrame(df.geo_zip.value_counts())\n",
    "df['latitude'] = zc.zip_to_lat_2(df.index)\n",
    "df['longitude'] = zc.zip_to_lon_2(df.index)\n",
    "\n",
    "dfratio = dftest/df\n",
    "dfratio['latitude'] = zc.zip_to_lat_2(dfratio.index)\n",
    "dfratio['longitude'] = zc.zip_to_lon_2(dfratio.index)\n",
    "\n",
    "df=df.dropna()\n",
    "dfratio=dfratio.dropna()\n",
    "\n",
    "df = df[['latitude','longitude','geo_zip']]\n",
    "df_copy = df.copy()\n",
    "\n",
    "dfratio = dfratio[['latitude','longitude','geo_zip']]\n",
    "dfratio_copy = dfratio.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Heatmap of ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[38.5, -100],zoom_start=4)\n",
    "HeatMap(data=df_copy[['latitude', 'longitude', 'geo_zip']].groupby(['latitude', 'longitude']).\\\n",
    "        sum().reset_index().values.tolist(), radius=6, max_zoom=13).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of (clicks/bids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mratio = folium.Map(location=[38.5, -100],zoom_start=4)\n",
    "HeatMap(data=dfratio_copy[['latitude', 'longitude', 'geo_zip']].groupby(['latitude', 'longitude']).\\\n",
    "        sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(mratio)\n",
    "mratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical encoding\n",
    "\n",
    "how you balance the data \n",
    "\n",
    "metrics for evaluating model fit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "trained on 1st 3 weeks:\n",
    "under sampled:\n",
    "![title](img\\RandomUnderSampler_firstweek.png)\n",
    "\n",
    "over sampled:\n",
    "![title](img\\RandomOverSampler_firstweek.png)\n",
    "\n",
    "same model applied to the last week:\n",
    "\n",
    "under sampled:\n",
    "![title](img\\RandomUnderSampler_lastweek.png)\n",
    "\n",
    "over sampled:\n",
    "![title](img\\RandomOverSampler_lastweek.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
